{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRnJsNfeiMyH"
      },
      "source": [
        "# CIFAR-10 dataset classification with CNNs\n",
        "\n",
        "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
        "\n",
        "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
        "\n",
        "First, the needed imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XXXfKtCJiMyO"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvAi_GQziMyQ"
      },
      "source": [
        "## CIFAR-10 data set\n",
        "\n",
        "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DJ1BlFHViMyR",
        "outputId": "ed8904c7-fa52-4092-a6fe-4ed33c76b2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "170508288/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL1KKT1iiMyS"
      },
      "source": [
        "This time we won't flatten the images. \n",
        "\n",
        "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 32x32 pixels. \n",
        "\n",
        "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H-n_oEqiMyT"
      },
      "source": [
        "## Convolutional neural network (CNN)\n",
        "\n",
        "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
        "\n",
        "Let's use a small model that includes convolutional layers\n",
        "\n",
        "- The Conv2D layers operate on 2D matrices so we input the images directly to the model.\n",
        "    - The two Conv2D layers below learn 32 and 64 filters respectively. \n",
        "    - They are learning filters for 3x3 windows.\n",
        "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
        "    - It downsamples by taking the maximum value in the window \n",
        "    - The pool size of (2, 2) below means the windows are 2x2. \n",
        "    - Helps in extracting important features and reduce computation\n",
        "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
        "\n",
        "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhdkonaAiMyV"
      },
      "source": [
        "![conv layer](https://github.com/aah217/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv_layer.png?raw=1)\n",
        "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM93IkyAiMyW"
      },
      "source": [
        "![conv layer](https://github.com/aah217/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/conv.png?raw=1)\n",
        "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbLNO16siMyX"
      },
      "source": [
        "\n",
        "<img src=\"https://github.com/aah217/ai-science-training-series/blob/main/03_neural_networks_tensorflow/images/MaxpoolSample2.png?raw=1\" width=\"600\" hight=\"600\" align=\"left\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6QT2WrG_iMyY"
      },
      "outputs": [],
      "source": [
        "class CIFAR10Classifier(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, activation=tf.nn.tanh):\n",
        "        tf.keras.models.Model.__init__(self)\n",
        "\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.drop_4 = tf.keras.layers.Dropout(0.25)\n",
        "        self.dense_5 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.drop_6 = tf.keras.layers.Dropout(0.5)\n",
        "        self.dense_7 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.pool_3(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.dense_5(x)\n",
        "        x = self.drop_6(x)\n",
        "        x = self.dense_7(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkbej7zBiMyZ"
      },
      "source": [
        "### Simple training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwHA6J0QiMyZ"
      },
      "source": [
        "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oQRAdFxoiMyZ"
      },
      "outputs": [],
      "source": [
        "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cnn_model = CIFAR10Classifier()\n",
        "\n",
        "    cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
        "    \n",
        "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PUFRjq2DiMya",
        "outputId": "e6bb7168-f10a-4565-aed3-3fe3f98169c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "98/98 [==============================] - 144s 1s/step - loss: 1.7292 - accuracy: 0.3719\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 140s 1s/step - loss: 1.3679 - accuracy: 0.5127\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 140s 1s/step - loss: 1.2267 - accuracy: 0.5651\n"
          ]
        }
      ],
      "source": [
        "# This took 43 seconds per epoch on my laptop\n",
        "batch_size = 512\n",
        "epochs = 3\n",
        "lr = .01\n",
        "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyycPBs0iMyb"
      },
      "source": [
        "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aklTcF_QiMyb",
        "outputId": "3e6d004a-bcd9-4387-b565-90d4fd7b5b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'])\n",
        "plt.title('accuracy');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqU16YK6iMyc"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-tqtfFyiMyc"
      },
      "source": [
        "With enough training epochs, the test accuracy should exceed 96.53%.\n",
        "\n",
        "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OZNH2Z4niMyc",
        "outputId": "664c07d9-a796-4b88-932b-29b0fdd1ab7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 7s - loss: 1.1027 - accuracy: 0.6122 - 7s/epoch - 24ms/step\n",
            "accuracy: 61.22%\n",
            "CPU times: user 13.5 s, sys: 229 ms, total: 13.7 s\n",
            "Wall time: 7.55 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuWKDeKpiMyd"
      },
      "source": [
        "We can also again check the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pZF0mcgtiMyd",
        "outputId": "06dd1b5e-8a20-43ce-b0db-f57ab0d45840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (rows: true classes; columns: predicted classes):\n",
            "\n",
            "[[691  37  33  16  21   3  20   4 125  50]\n",
            " [ 28 793   3   2   2   2  17   6  35 112]\n",
            " [ 93  17 319  43 167  81 195  37  28  20]\n",
            " [ 24  26  48 336 103 122 252  34  17  38]\n",
            " [ 41  12  40  43 548  14 226  53  20   3]\n",
            " [ 20   9  50 171  98 447 108  61  20  16]\n",
            " [  5  13  18  25  25   6 887   5   7   9]\n",
            " [ 25   9  22  36  96  59  48 651   9  45]\n",
            " [ 96  88   6  10   4   3  17   5 722  49]\n",
            " [ 42 140   6   9   5   3  17  13  37 728]]\n",
            "\n",
            "Classification accuracy for each class:\n",
            "\n",
            "0: 0.6910\n",
            "1: 0.7930\n",
            "2: 0.3190\n",
            "3: 0.3360\n",
            "4: 0.5480\n",
            "5: 0.4470\n",
            "6: 0.8870\n",
            "7: 0.6510\n",
            "8: 0.7220\n",
            "9: 0.7280\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
        "predictions = cnn_model.predict(x_test)\n",
        "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
        "print(cm); print()\n",
        "\n",
        "print('Classification accuracy for each class:'); print()\n",
        "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6mcxq3qiMyd"
      },
      "source": [
        "### More verbose training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCYZXybOiMye"
      },
      "source": [
        "This approach explicitly handles the looping over data. It will be helpful in future weeks for diving in and optimizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8WUCPr3giMye"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y_true, y_pred):\n",
        "    # if labels are integers, use sparse categorical crossentropy\n",
        "    # network's final layer is softmax, so from_logtis=False\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    # if labels are one-hot encoded, use standard crossentropy\n",
        "\n",
        "    return scce(y_true, y_pred)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GZqek6wwiMye"
      },
      "outputs": [],
      "source": [
        "def forward_pass(model, batch_data, y_true):\n",
        "    y_pred = model(batch_data)\n",
        "    loss = compute_loss(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tUD-2RnKiMyf"
      },
      "outputs": [],
      "source": [
        "# Here is a function that will manage the training loop for us:\n",
        "\n",
        "def train_loop(batch_size, n_training_epochs, model, opt):\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_iteration(data, y_true, model, opt):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = forward_pass(model, data, y_true)\n",
        "\n",
        "        trainable_vars = model.trainable_variables\n",
        "\n",
        "        # Apply the update to the network (one at a time):\n",
        "        grads = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        opt.apply_gradients(zip(grads, trainable_vars))\n",
        "        return loss\n",
        "\n",
        "    for i_epoch in range(n_training_epochs):\n",
        "        print(\"beginning epoch %d\" % i_epoch)\n",
        "        start = time.time()\n",
        "\n",
        "        epoch_steps = int(50000/batch_size)\n",
        "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
        "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "        \n",
        "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
        "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
        "            loss = train_iteration(batch_data, y_true, model, opt)\n",
        "            \n",
        "        end = time.time()\n",
        "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "swttBwIiiMyf"
      },
      "outputs": [],
      "source": [
        "def train_network(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cifar_model = CIFAR10Classifier()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(_lr)\n",
        "\n",
        "    train_loop(_batch_size, _n_training_epochs, cifar_model, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0sh4IocgiMyf",
        "outputId": "29c533fd-4066-4151-aad4-f36b6cf043e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beginning epoch 0\n",
            "took 131.7 seconds for epoch #0\n",
            "beginning epoch 1\n",
            "took 130.2 seconds for epoch #1\n",
            "beginning epoch 2\n",
            "took 130.5 seconds for epoch #2\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset.shuffle(50000)\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 3\n",
        "lr = .01\n",
        "train_network(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoP7cIsbiMyf"
      },
      "source": [
        "# Homework: improve the accuracy of this model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si-kW8aYiMyg"
      },
      "source": [
        "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning rate, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l6l25PMfiMyg",
        "outputId": "33a27b22-212a-49f5-f6c0-f22b91a1e1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "25/25 [==============================] - 146s 6s/step - loss: 2.1470 - accuracy: 0.2046\n",
            "Epoch 2/3\n",
            "25/25 [==============================] - 142s 6s/step - loss: 1.8315 - accuracy: 0.3343\n",
            "Epoch 3/3\n",
            "25/25 [==============================] - 142s 6s/step - loss: 1.6572 - accuracy: 0.4003\n",
            "313/313 - 11s - loss: 1.4579 - accuracy: 0.4980 - 11s/epoch - 35ms/step\n",
            "Batch size 2048\n",
            "accuracy: 49.80%\n",
            "Epoch 1/3\n",
            "49/49 [==============================] - 138s 3s/step - loss: 2.0539 - accuracy: 0.2414\n",
            "Epoch 2/3\n",
            "49/49 [==============================] - 140s 3s/step - loss: 1.6942 - accuracy: 0.3837\n",
            "Epoch 3/3\n",
            "49/49 [==============================] - 139s 3s/step - loss: 1.5295 - accuracy: 0.4458\n",
            "313/313 - 8s - loss: 1.3451 - accuracy: 0.5245 - 8s/epoch - 26ms/step\n",
            "Batch size 1024\n",
            "accuracy: 52.45%\n",
            "Epoch 1/3\n",
            "98/98 [==============================] - 141s 1s/step - loss: 1.8237 - accuracy: 0.3343\n",
            "Epoch 2/3\n",
            "98/98 [==============================] - 139s 1s/step - loss: 1.4641 - accuracy: 0.4762\n",
            "Epoch 3/3\n",
            "98/98 [==============================] - 140s 1s/step - loss: 1.3185 - accuracy: 0.5299\n",
            "313/313 - 7s - loss: 1.1462 - accuracy: 0.5986 - 7s/epoch - 24ms/step\n",
            "Batch size 512\n",
            "accuracy: 59.86%\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 145s 737ms/step - loss: 1.6871 - accuracy: 0.3858\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 144s 737ms/step - loss: 1.3531 - accuracy: 0.5148\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 144s 734ms/step - loss: 1.2134 - accuracy: 0.5691\n",
            "313/313 - 8s - loss: 1.0815 - accuracy: 0.6196 - 8s/epoch - 26ms/step\n",
            "Batch size 256\n",
            "accuracy: 61.96%\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 153s 389ms/step - loss: 1.7324 - accuracy: 0.3629\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 152s 387ms/step - loss: 1.3967 - accuracy: 0.4979\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 152s 389ms/step - loss: 1.2719 - accuracy: 0.5474\n",
            "313/313 - 8s - loss: 1.0877 - accuracy: 0.6194 - 8s/epoch - 26ms/step\n",
            "Batch size 128\n",
            "accuracy: 61.94%\n"
          ]
        }
      ],
      "source": [
        "#parameter scan batch_size\n",
        "for batch_size in (2048,1024,512,256,128):\n",
        "  epochs = 3\n",
        "  lr = .01\n",
        "  history, cnn_model = train_network_concise(batch_size, epochs, lr)\n",
        "  x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "  scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "  print(\"Batch size\",batch_size)\n",
        "  print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter scan learning rate\n",
        "for lr in (1,0.1,0.01,0.001,0.0001):\n",
        "  batch_size = 256\n",
        "  epochs = 3\n",
        "  history, cnn_model = train_network_concise(batch_size, epochs, lr)\n",
        "  x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "  scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "  print(\"Learning rate\",lr)\n",
        "  print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "mk-X9vgovs5a",
        "outputId": "49b88c72-78db-49e3-9186-7e2e7cb2a6cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "196/196 [==============================] - 163s 829ms/step - loss: 1.6853 - accuracy: 0.3853\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 159s 809ms/step - loss: 1.3348 - accuracy: 0.5217\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 155s 789ms/step - loss: 1.1943 - accuracy: 0.5773\n",
            "313/313 - 8s - loss: 1.0480 - accuracy: 0.6329 - 8s/epoch - 25ms/step\n",
            "Learning rate 1\n",
            "accuracy: 63.29%\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 157s 798ms/step - loss: 1.6961 - accuracy: 0.3817\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 154s 785ms/step - loss: 1.3543 - accuracy: 0.5169\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 154s 785ms/step - loss: 1.2169 - accuracy: 0.5684\n",
            "313/313 - 8s - loss: 1.0494 - accuracy: 0.6372 - 8s/epoch - 26ms/step\n",
            "Learning rate 0.1\n",
            "accuracy: 63.72%\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 153s 771ms/step - loss: 1.7423 - accuracy: 0.3652\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 149s 762ms/step - loss: 1.4222 - accuracy: 0.4907\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 149s 761ms/step - loss: 1.2802 - accuracy: 0.5424\n",
            "313/313 - 8s - loss: 1.1154 - accuracy: 0.6029 - 8s/epoch - 25ms/step\n",
            "Learning rate 0.01\n",
            "accuracy: 60.29%\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 152s 775ms/step - loss: 1.6623 - accuracy: 0.3945\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 154s 785ms/step - loss: 1.3135 - accuracy: 0.5319\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 152s 774ms/step - loss: 1.1712 - accuracy: 0.5896\n",
            "313/313 - 8s - loss: 1.0227 - accuracy: 0.6399 - 8s/epoch - 25ms/step\n",
            "Learning rate 0.001\n",
            "accuracy: 63.99%\n",
            "Epoch 1/3\n",
            "196/196 [==============================] - 154s 782ms/step - loss: 1.7106 - accuracy: 0.3779\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 152s 775ms/step - loss: 1.3428 - accuracy: 0.5205\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 151s 772ms/step - loss: 1.2013 - accuracy: 0.5744\n",
            "313/313 - 8s - loss: 1.0558 - accuracy: 0.6399 - 8s/epoch - 26ms/step\n",
            "Learning rate 0.0001\n",
            "accuracy: 63.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#parameter scan epochs\n",
        "for epochs in (3,6,9,12):\n",
        "  batch_size = 256\n",
        "  lr = 0.0001\n",
        "  history, cnn_model = train_network_concise(batch_size, epochs, lr)\n",
        "  x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "  scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "  print(\"epochs\",epochs)\n",
        "  print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "id": "IoTs2vitEXLQ",
        "outputId": "a8c37dd2-327c-424b-ce70-9f7636dc3872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "196/196 [==============================] - 154s 784ms/step - loss: 1.7406 - accuracy: 0.3666\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 154s 787ms/step - loss: 1.3839 - accuracy: 0.5046\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 155s 790ms/step - loss: 1.2496 - accuracy: 0.5541\n",
            "313/313 - 8s - loss: 1.0973 - accuracy: 0.6164 - 8s/epoch - 25ms/step\n",
            "epochs 3\n",
            "accuracy: 61.64%\n",
            "Epoch 1/6\n",
            "196/196 [==============================] - 154s 785ms/step - loss: 1.6953 - accuracy: 0.3818\n",
            "Epoch 2/6\n",
            "196/196 [==============================] - 154s 786ms/step - loss: 1.3387 - accuracy: 0.5243\n",
            "Epoch 3/6\n",
            "196/196 [==============================] - 155s 791ms/step - loss: 1.1922 - accuracy: 0.5788\n",
            "Epoch 4/6\n",
            "196/196 [==============================] - 157s 803ms/step - loss: 1.1197 - accuracy: 0.6035\n",
            "Epoch 5/6\n",
            "196/196 [==============================] - 154s 786ms/step - loss: 1.0644 - accuracy: 0.6259\n",
            "Epoch 6/6\n",
            "196/196 [==============================] - 153s 783ms/step - loss: 1.0124 - accuracy: 0.6406\n",
            "313/313 - 8s - loss: 0.9286 - accuracy: 0.6785 - 8s/epoch - 25ms/step\n",
            "epochs 6\n",
            "accuracy: 67.85%\n",
            "Epoch 1/9\n",
            "196/196 [==============================] - 153s 776ms/step - loss: 1.7025 - accuracy: 0.3804\n",
            "Epoch 2/9\n",
            "196/196 [==============================] - 151s 768ms/step - loss: 1.3410 - accuracy: 0.5212\n",
            "Epoch 3/9\n",
            "196/196 [==============================] - 151s 768ms/step - loss: 1.2043 - accuracy: 0.5742\n",
            "Epoch 4/9\n",
            "196/196 [==============================] - 150s 767ms/step - loss: 1.1145 - accuracy: 0.6051\n",
            "Epoch 5/9\n",
            "196/196 [==============================] - 149s 763ms/step - loss: 1.0584 - accuracy: 0.6271\n",
            "Epoch 6/9\n",
            "196/196 [==============================] - 149s 759ms/step - loss: 1.0099 - accuracy: 0.6442\n",
            "Epoch 7/9\n",
            "196/196 [==============================] - 154s 788ms/step - loss: 0.9649 - accuracy: 0.6578\n",
            "Epoch 8/9\n",
            "196/196 [==============================] - 151s 769ms/step - loss: 0.9184 - accuracy: 0.6760\n",
            "Epoch 9/9\n",
            "196/196 [==============================] - 152s 776ms/step - loss: 0.8880 - accuracy: 0.6849\n",
            "313/313 - 9s - loss: 0.9163 - accuracy: 0.6807 - 9s/epoch - 29ms/step\n",
            "epochs 9\n",
            "accuracy: 68.07%\n",
            "Epoch 1/12\n",
            "196/196 [==============================] - 152s 774ms/step - loss: 1.7495 - accuracy: 0.3651\n",
            "Epoch 2/12\n",
            "196/196 [==============================] - 154s 785ms/step - loss: 1.4102 - accuracy: 0.4950\n",
            "Epoch 3/12\n",
            "196/196 [==============================] - 154s 787ms/step - loss: 1.2703 - accuracy: 0.5486\n",
            "Epoch 4/12\n",
            "196/196 [==============================] - 153s 781ms/step - loss: 1.1826 - accuracy: 0.5801\n",
            "Epoch 5/12\n",
            "196/196 [==============================] - 153s 779ms/step - loss: 1.1074 - accuracy: 0.6085\n",
            "Epoch 6/12\n",
            "196/196 [==============================] - 153s 783ms/step - loss: 1.0570 - accuracy: 0.6275\n",
            "Epoch 7/12\n",
            "196/196 [==============================] - 153s 779ms/step - loss: 1.0084 - accuracy: 0.6410\n",
            "Epoch 8/12\n",
            "196/196 [==============================] - 153s 779ms/step - loss: 0.9636 - accuracy: 0.6604\n",
            "Epoch 9/12\n",
            "196/196 [==============================] - 153s 779ms/step - loss: 0.9217 - accuracy: 0.6733\n",
            "Epoch 10/12\n",
            "196/196 [==============================] - 155s 789ms/step - loss: 0.8927 - accuracy: 0.6832\n",
            "Epoch 11/12\n",
            "196/196 [==============================] - 155s 792ms/step - loss: 0.8674 - accuracy: 0.6912\n",
            "Epoch 12/12\n",
            "196/196 [==============================] - 154s 786ms/step - loss: 0.8420 - accuracy: 0.7012\n",
            "313/313 - 8s - loss: 0.8742 - accuracy: 0.6954 - 8s/epoch - 25ms/step\n",
            "epochs 12\n",
            "accuracy: 69.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowering batch size improved accuracy but seemed to reach a plateau around a batch size of 256. Lowering learning rate had only a small effect on accuracy. Increasing number of epochs improved accuracy up to close to 70% but seemingly has not yet plateaued. Stopped checking at 12 epochs as it's a slow process."
      ],
      "metadata": {
        "id": "kYHXJh8qDjY-"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}